# Copyright (c) OpenMMLab. All rights reserved.
from typing import Callable, Dict, Optional, Sequence, Tuple, Union

import mmengine
import numpy as np
import torch
from mmagic.models.utils.sampling_utils import noise_sample_fn
from mmengine.model import BaseDataPreprocessor

from mmdeploy.codebase import BaseTask
from mmdeploy.codebase.mmagic.deploy.mmediting import MMAGIC_TASK
from mmdeploy.utils import Task


def _fetch_pred_hook(model: torch.nn.Module, args, outputs):
    results = []
    for output in outputs:
        results.append(output.fake_img)
    return torch.stack(results)


@MMAGIC_TASK.register_module(Task.UNCONDITIONAL_GAN.value)
class UnconditionalGAN(BaseTask):
    """"""

    def __init__(self, model_cfg: mmengine.Config, deploy_cfg: mmengine.Config,
                 device: str):
        super(UnconditionalGAN, self).__init__(model_cfg, deploy_cfg, device)
        import mmcv
        mmcv.ops.conv2d_gradfix.enabled = False

    def build_backend_model(
            self,
            model_files: Sequence[str] = None,
            data_preprocessor_updater: Optional[Callable] = None,
            **kwargs) -> torch.nn.Module:
        raise NotImplementedError

    def build_pytorch_model(self,
                            model_checkpoint: Optional[str] = None,
                            cfg_options: Optional[Dict] = None,
                            **kwargs) -> torch.nn.Module:
        """Initialize torch model.

        Args:
            model_checkpoint (str): The checkpoint file of torch model,
                defaults to `None`.
            cfg_options (dict): Optional config key-pair parameters.

        Returns:
            nn.Module: An initialized torch model generated by other OpenMMLab
                codebases.
        """
        model = super().build_pytorch_model(model_checkpoint, cfg_options,
                                            **kwargs)

        model.register_forward_hook(_fetch_pred_hook)
        return model

    def create_input(
        self,
        imgs: Union[str, np.ndarray],
        input_shape: Sequence[int] = None,
        data_preprocessor: Optional[BaseDataPreprocessor] = None,
    ) -> Tuple[Dict, torch.Tensor]:
        """Create a pseudo input for unconditional GAN task."""
        # TODO: deal with variable input_shape
        num_batches = self.model_cfg.batch_size
        noise_size = self.model_cfg.model.generator.style_channels
        noise = noise_sample_fn(
            noise=None,
            num_batches=num_batches,
            noise_size=noise_size,
            device=self.device,
        )

        return {'inputs': noise, 'data_samples': None}, noise

    @staticmethod
    def get_partition_cfg(partition_type: str, **kwargs) -> Dict:
        """Get a certain partition config for mmagic.

        Args:
            partition_type (str): A string specifying partition type.

        Returns:
            dict: A dictionary of partition config.
        """
        raise NotImplementedError

    def get_preprocess(self, *args, **kwargs) -> Dict:
        pass

    def get_postprocess(self, *args, **kwargs) -> Dict:
        pass

    def get_model_name(self, *args, **kwargs) -> str:
        """Get the model name.

        Return:
            str: the name of the model.
        """
        assert 'type' in self.model_cfg.model, 'model contains no type'
        name = self.model_cfg.model.type.lower()
        return name
